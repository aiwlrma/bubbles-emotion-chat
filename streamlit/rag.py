import os
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib.enums import TA_CENTER
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import io
import json
import streamlit as st
from datetime import date
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Initialize OpenAI client
client = None
try:
    from openai import OpenAI
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
    if OPENAI_API_KEY:
        client = OpenAI(api_key=OPENAI_API_KEY)
except ImportError:
    st.error("OpenAI package not installed. Please install it with: pip install openai")
except Exception as e:
    st.warning(f"OpenAI client initialization failed: {e}")

def load_rag_documents(rag_folder):
    """Load RAG documents for guidance generation"""
    EMOTION_GUIDANCE_DOCS = {
        "positive_reinforcement": """ê¸ì •ì  ê°ì • ê°•í™” ê°€ì´ë“œ:
- ì•„ì´ê°€ ê¸ì •ì ì¸ ê°ì •ì„ í‘œí˜„í–ˆì„ ë•ŒëŠ” êµ¬ì²´ì ìœ¼ë¡œ ì¹­ì°¬í•´ì£¼ì„¸ìš”
- 'ì •ë§ ì˜í–ˆë„¤!', 'ë„¤ê°€ í–‰ë³µí•´í•˜ë‹ˆ ë‚˜ë„ ê¸°ë»' ê°™ì€ ê³µê° í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ê¸ì •ì  ê²½í—˜ì„ ë” ìì„¸íˆ ì´ì•¼ê¸°í•˜ë„ë¡ ê²©ë ¤í•´ì£¼ì„¸ìš”
- ê°ì •ì„ í‘œí˜„í•œ ê²ƒ ìì²´ë¥¼ ì¹­ì°¬í•´ì£¼ì„¸ìš”
- ê¸ì •ì ì¸ ìˆœê°„ë“¤ì„ ê¸°ë¡í•˜ê³  ë‚˜ì¤‘ì— ë‹¤ì‹œ ì´ì•¼ê¸°í•´ë³´ì„¸ìš”""",
        
        "negative_support": """ë¶€ì •ì  ê°ì • ì§€ì› ê°€ì´ë“œ:
- ë¨¼ì € ì•„ì´ì˜ ê°ì •ì„ ì¸ì •í•˜ê³  ê³µê°í•´ì£¼ì„¸ìš”
- 'ë§ì´ ì†ìƒí–ˆê² êµ¬ë‚˜', 'í˜ë“¤ì—ˆê² ë„¤' ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”
- í•´ê²°ì±…ì„ ë°”ë¡œ ì œì‹œí•˜ê¸°ë³´ë‹¤ ì¶©ë¶„íˆ ë“¤ì–´ì£¼ì„¸ìš”
- ì•ˆì „í•˜ê³  í¸ì•ˆí•œ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±í•´ì£¼ì„¸ìš”
- ì•„ì´ê°€ ê°ì •ì„ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì„ ì œì‹œí•´ì£¼ì„¸ìš”
- ë¶€ì •ì  ê°ì •ë„ ìì—°ìŠ¤ëŸ½ê³  ì†Œì¤‘í•œ ê²ƒì„ì„ ì•Œë ¤ì£¼ì„¸ìš”""",
        
        "conversation_tips": """íš¨ê³¼ì ì¸ ëŒ€í™” íŒ:
- ì•„ì´ì˜ ëˆˆë†’ì´ì— ë§ì¶° ëŒ€í™”í•˜ì„¸ìš”
- ì—´ë¦° ì§ˆë¬¸ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš” ('ì–´ë–»ê²Œ ëŠê¼ˆì–´?', 'ë” ìì„¸íˆ ë§í•´ì¤„ë˜?')
- íŒë‹¨í•˜ì§€ ì•Šê³  ê²½ì²­í•˜ì„¸ìš”
- ì•„ì´ì˜ ì†ë„ì— ë§ì¶° ëŒ€í™”í•˜ì„¸ìš”
- ì¼ìƒì ì¸ ìˆœê°„ë“¤ì„ ëŒ€í™”ì˜ ê¸°íšŒë¡œ í™œìš©í•˜ì„¸ìš”
- ì•„ì´ì˜ ê°ì •ì„ ë°˜ì˜í•´ì„œ ë‹¤ì‹œ ë§í•´ì£¼ì„¸ìš”""",
        
        "emotional_development": """ê°ì • ë°œë‹¬ ì´í•´:
- ì—°ë ¹ë³„ ê°ì • í‘œí˜„ì˜ ì°¨ì´ë¥¼ ì´í•´í•˜ì„¸ìš”
- ê°ì • ì–´íœ˜ë¥¼ í™•ì¥ì‹œì¼œì£¼ì„¸ìš” ('ê¸°ì˜ë‹¤' ì™¸ì— 'ì‹ ë‚˜ë‹¤', 'ë¿Œë“¯í•˜ë‹¤' ë“±)
- ë‹¤ì–‘í•œ ê°ì •ì„ ì¸ì •í•˜ê³  ìˆ˜ìš©í•´ì£¼ì„¸ìš”
- ê°ì • ì¡°ì ˆ ë°©ë²•ì„ í•¨ê»˜ ì°¾ì•„ê°€ì„¸ìš”
- ê°ì •ê³¼ í–‰ë™ì„ ë¶„ë¦¬í•´ì„œ ì´í•´í•˜ë„ë¡ ë„ì™€ì£¼ì„¸ìš”
- ê°ì • í‘œí˜„ì˜ ëª¨ë¸ì´ ë˜ì–´ì£¼ì„¸ìš”"""
    }
    
    # Try to load additional documents from rag folder if it exists
    if os.path.exists(rag_folder) and os.path.isdir(rag_folder):
        try:
            for filename in os.listdir(rag_folder):
                if filename.endswith(".txt"):
                    file_path = os.path.join(rag_folder, filename)
                    with open(file_path, 'r', encoding='utf-8') as file:
                        key = os.path.splitext(filename)[0]
                        EMOTION_GUIDANCE_DOCS[key] = file.read().strip()
        except Exception as e:
            st.warning(f"Could not load additional RAG documents: {e}")
    
    return EMOTION_GUIDANCE_DOCS

def generate_rag_based_report(history_data, rag_docs):
    """Generate AI-based guidance report using RAG documents"""
    
    # Check if we have data
    if not history_data:
        return "ì•„ì§ ì˜¤ëŠ˜ ì•„ì´ì˜ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤. ì•„ì´ê°€ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë©´ ë¶„ì„ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤."
    
    # Check API key
    if not client:
        return """OpenAI APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤:

ğŸ“Š **ì˜¤ëŠ˜ì˜ ê°ì • ë¶„ì„**
- ì´ ëŒ€í™”: {}íšŒ
- ì•„ì´ê°€ ë‹¤ì–‘í•œ ê°ì •ì„ í‘œí˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ğŸ’¡ **ë¶€ëª¨ë‹˜ì„ ìœ„í•œ ì¡°ì–¸**
1. **ê²½ì²­í•˜ê¸°**: ì•„ì´ì˜ ì´ì•¼ê¸°ë¥¼ ëê¹Œì§€ ë“¤ì–´ì£¼ì„¸ìš”
2. **ê³µê°í•˜ê¸°**: "ê·¸ë¬êµ¬ë‚˜", "í˜ë“¤ì—ˆê² ë„¤" ê°™ì€ ê³µê° í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”  
3. **ê²©ë ¤í•˜ê¸°**: ê°ì •ì„ í‘œí˜„í•œ ê²ƒ ìì²´ë¥¼ ì¹­ì°¬í•´ì£¼ì„¸ìš”

ğŸŒŸ **ì¶”ì²œ ëŒ€í™”ë²•**
- "ì˜¤ëŠ˜ ì–´ë–¤ ê¸°ë¶„ì´ì—ˆì–´?"
- "ê·¸ë•Œ ì–´ë–¤ ìƒê°ì´ ë“¤ì—ˆì–´?"
- "ë„¤ ë§ˆìŒì„ ì´í•´í•  ê²ƒ ê°™ì•„"

ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ì•„ì´ì™€ ê¾¸ì¤€íˆ ì†Œí†µí•´ë³´ì„¸ìš”!""".format(len(history_data))
    
    # Calculate metrics
    positive_count = sum(1 for h in history_data if h["emotion"] == "Positive")
    negative_count = len(history_data) - positive_count
    total_count = len(history_data)
    pos_ratio = (positive_count / total_count * 100) if total_count > 0 else 0
    
    # Select relevant documents based on emotion analysis
    relevant_docs = []
    if pos_ratio >= 70:
        relevant_docs.append(rag_docs.get("positive_reinforcement", ""))
    if negative_count > 0:
        relevant_docs.append(rag_docs.get("negative_support", ""))
    
    # Always include conversation tips and emotional development
    relevant_docs.append(rag_docs.get("conversation_tips", ""))
    relevant_docs.append(rag_docs.get("emotional_development", ""))
    
    # Create context from relevant documents
    context = "\n\n".join(filter(None, relevant_docs))
    
    # Create conversation summary (limit to last 5 conversations for context)
    conversations = []
    for h in history_data[-5:]:
        time = h['timestamp'].split()[1] if ' ' in h['timestamp'] else h['timestamp']
        conversations.append(f"- {time}: {h['answer'][:100]}... (ê°ì •: {h['emotion']}, ì‹ ë¢°ë„: {h['confidence']:.1%})")
    
    conversations_text = "\n".join(conversations)
    
    # Create prompt for OpenAI
    prompt = f"""ë‹¹ì‹ ì€ ì•„ë™ ì‹¬ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶€ëª¨ë‹˜ì„ ìœ„í•œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ì „ë¬¸ê°€ ê°€ì´ë“œë¼ì¸]
{context}

[ì˜¤ëŠ˜ì˜ ì•„ì´ ëŒ€í™” ê¸°ë¡]
{conversations_text}

[ê°ì • ë¶„ì„ ê²°ê³¼]
- ì´ ëŒ€í™”: {total_count}íšŒ
- ê¸ì •ì  ê°ì •: {positive_count}íšŒ ({pos_ratio:.0f}%)
- ë¶€ì •ì  ê°ì •: {negative_count}íšŒ ({100-pos_ratio:.0f}%)

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶€ëª¨ë‹˜ê»˜ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ ì¡°ì–¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. **ì˜¤ëŠ˜ì˜ ê°ì • ìƒíƒœ ìš”ì•½** (2-3ë¬¸ì¥)
2. **êµ¬ì²´ì ì¸ ëŒ€í™” ë°©ë²• 3ê°€ì§€** (ì‹¤ì œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¬¸ì¥ ì˜ˆì‹œ í¬í•¨)
3. **ì£¼ì˜ì‚¬í•­ ë° ê¶Œì¥ì‚¬í•­** (2-3ê°œ)
4. **ê²©ë ¤ ë©”ì‹œì§€** (ë¶€ëª¨ë‹˜ì„ ìœ„í•œ)

ë”°ëœ»í•˜ê³  ì‹¤ìš©ì ì´ë©° ì „ë¬¸ì ì¸ ì¡°ì–¸ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ì„œ ì½ê¸° ì‰½ê²Œ í•´ì£¼ì„¸ìš”."""

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1200
        )
        return response.choices[0].message.content.strip()
    
    except Exception as e:
        st.error(f"AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        
        # Provide fallback report
        return f"""ğŸ“Š **ì˜¤ëŠ˜ì˜ ê°ì • ë¶„ì„**

ì´ {total_count}íšŒì˜ ëŒ€í™”ì—ì„œ ê¸ì •ì  ê°ì •ì´ {pos_ratio:.0f}%ë¥¼ ì°¨ì§€í–ˆìŠµë‹ˆë‹¤.

ğŸ’¡ **ë¶€ëª¨ë‹˜ì„ ìœ„í•œ ì¡°ì–¸**

1. **ê²½ì²­ì˜ í˜**: ì•„ì´ì˜ ì´ì•¼ê¸°ë¥¼ ëê¹Œì§€ ë“¤ì–´ì£¼ì„¸ìš”. "ê·¸ë¬êµ¬ë‚˜", "ë” ë§í•´ë³¼ë˜?" ê°™ì€ ë°˜ì‘ì„ ë³´ì—¬ì£¼ì„¸ìš”.

2. **ê°ì • ì¸ì •í•˜ê¸°**: {"ê¸ì •ì ì¸ ê°ì •ì„ ë” ê²©ë ¤í•´ì£¼ì„¸ìš”. 'ë„¤ê°€ ê¸°ë»í•˜ë‹ˆ ë‚˜ë„ ê¸°ë»!' ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”." if pos_ratio >= 70 else "ë¶€ì •ì ì¸ ê°ì •ë„ ìì—°ìŠ¤ëŸ¬ìš´ ê²ƒì„ì„ ì•Œë ¤ì£¼ì„¸ìš”. 'í˜ë“¤ì—ˆê² êµ¬ë‚˜' í•˜ë©° ê³µê°í•´ì£¼ì„¸ìš”."}

3. **ê¾¸ì¤€í•œ ì†Œí†µ**: ë§¤ì¼ ì¡°ê¸ˆì”©ì´ë¼ë„ ì•„ì´ì™€ ê°ì •ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ë³´ì„¸ìš”.

ğŸŒŸ **ì˜¤ëŠ˜ í•˜ë£¨ë„ ì•„ì´ì™€ ì†Œì¤‘í•œ ì‹œê°„ì„ ë³´ë‚´ì…¨ë„¤ìš”. ê¾¸ì¤€í•œ ê´€ì‹¬ê³¼ ì‚¬ë‘ì´ ì•„ì´ì˜ ê°ì • ë°œë‹¬ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤!**"""

def create_pdf_report(history_data, report_content, font_path):
    """Create PDF report with emotion data and AI guidance"""
    
    if not history_data:
        st.warning("PDFë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    story = []
    
    # Try to register Korean font
    try:
        if os.path.exists(font_path):
            pdfmetrics.registerFont(TTFont('NotoSansCJKkr', font_path))
            font_name = 'NotoSansCJKkr'
        else:
            st.warning("í•œê¸€ í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            font_name = 'Helvetica'
    except Exception as e:
        st.warning(f"í°íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        font_name = 'Helvetica'
    
    # Define styles
    styles = getSampleStyleSheet()
    
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        textColor=colors.HexColor('#6366f1'),
        alignment=TA_CENTER,
        spaceAfter=30,
        fontName=font_name
    )
    
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading2'],
        fontSize=16,
        textColor=colors.HexColor('#4f46e5'),
        spaceAfter=12,
        fontName=font_name
    )
    
    normal_style = ParagraphStyle(
        'CustomNormal',
        parent=styles['Normal'],
        fontSize=11,
        leading=16,
        fontName=font_name
    )
    
    # Add title and date
    story.append(Paragraph("Child Emotion Report", title_style))
    story.append(Paragraph(f"Report Date: {date.today().strftime('%Y-%m-%d')}", normal_style))
    story.append(Spacer(1, 0.5*inch))
    
    # Add summary section
    story.append(Paragraph("Today's Summary", heading_style))
    positive_count = sum(1 for h in history_data if h["emotion"] == "Positive")
    negative_count = len(history_data) - positive_count
    total = len(history_data)
    
    summary_data = [
        ['Category', 'Value'],
        ['Total Conversations', str(total)],
        ['Positive Emotions', f"{positive_count} ({positive_count/total*100:.0f}%)"],
        ['Negative Emotions', f"{negative_count} ({negative_count/total*100:.0f}%)"]
    ]
    
    summary_table = Table(summary_data, colWidths=[3*inch, 2*inch])
    summary_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#e0e7ff')),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor('#4f46e5')),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, -1), font_name),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('FONTSIZE', (0, 1), (-1, -1), 10),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('GRID', (0, 0), (-1, -1), 1, colors.grey)
    ]))
    
    story.append(summary_table)
    story.append(Spacer(1, 0.5*inch))
    
    # Add conversation history
    story.append(Paragraph("Conversation History", heading_style))
    for i, item in enumerate(history_data[:10], 1):
        time = item['timestamp'].split()[1] if ' ' in item['timestamp'] else item['timestamp']
        emotion = "Positive" if item["emotion"] == "Positive" else "Negative"
        confidence = item.get('confidence', 0)
        
        conv_text = f"""<b>{i}. Time:</b> {time} | <b>Emotion:</b> {emotion} ({confidence:.0%})<br/>
<b>Content:</b> {item['answer'][:200]}{'...' if len(item['answer']) > 200 else ''}<br/><br/>"""
        
        story.append(Paragraph(conv_text, normal_style))
    
    # Add AI recommendations if available
    if report_content and report_content.strip():
        story.append(Spacer(1, 0.3*inch))
        story.append(Paragraph("AI Recommendations", heading_style))
        # Clean up the report content for PDF
        clean_content = report_content.replace('**', '<b>').replace('**', '</b>')
        clean_content = clean_content.replace('*', 'â€¢')
        story.append(Paragraph(clean_content, normal_style))
    
    try:
        doc.build(story)
        buffer.seek(0)
        return buffer
    except Exception as e:
        st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None
