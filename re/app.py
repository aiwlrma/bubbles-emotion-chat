import os
import random
import streamlit as st
from dotenv import load_dotenv
from datetime import datetime, date
from openai import OpenAI
from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# --- 1. í™˜ê²½ ë³€ìˆ˜ ë° API/ì¸ì¦ ì½”ë“œ ë¡œë“œ ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PARENT_CODE = os.getenv("PARENT_CODE", "1234")
client = OpenAI(api_key=OPENAI_API_KEY)

# --- 2. ì˜¤ëŠ˜ì˜ ì§ˆë¬¸ ---
@st.cache_data
def get_questions():
    return [
        "ì˜¤ëŠ˜ ê°€ì¥ ê¸°ë»¤ë˜ ì¼ì€ ë­ì˜€ì–´?",
        "ì˜¤ëŠ˜ ì†ìƒí–ˆë˜ ì¼ì´ ìˆì—ˆë‹ˆ?",
        "ì¹œêµ¬ì™€ ì¬ë¯¸ìˆê²Œ ë†€ì•˜ë˜ ìˆœê°„ì„ ì´ì•¼ê¸°í•´ì¤„ë˜?",
        "ì˜¤ëŠ˜ í•™êµ(ìœ ì¹˜ì›)ì—ì„œ ë°°ìš´ ê²ƒ ì¤‘ ê¸°ì–µì— ë‚¨ëŠ” ê²Œ ìˆë‹ˆ?",
        "ì˜¤ëŠ˜ ëˆ„êµ°ê°€ì—ê²Œ ê³ ë§ˆì› ë˜ ì¼ì´ ìˆì—ˆë‹ˆ?",
        "ì˜¤ëŠ˜ í•˜ë£¨ ì¤‘ ê°€ì¥ í˜ë“¤ì—ˆë˜ ìˆœê°„ì€ ì–¸ì œì˜€ì–´?",
        "ì˜¤ëŠ˜ ì—„ë§ˆ(ì•„ë¹ )ì—ê²Œ í•´ì£¼ê³  ì‹¶ì€ ë§ì´ ìˆë‹ˆ?",
        "ì˜¤ëŠ˜ ìƒˆë¡œìš´ ê²ƒì„ ì‹œë„í•´ë³¸ ì ì´ ìˆë‹ˆ?",
        "ì˜¤ëŠ˜ ê°€ì¥ ë§ì´ ì›ƒì—ˆë˜ ìˆœê°„ì€?",
        "ì˜¤ëŠ˜ í˜¼ìë§Œì˜ ì‹œê°„ì´ í•„ìš”í–ˆë˜ ì ì´ ìˆì—ˆë‹ˆ?"
    ]

def get_today_question():
    today = date.today().isoformat()
    if "today_question" not in st.session_state or st.session_state.get("question_date") != today:
        questions = get_questions()
        question = random.choice(questions)
        st.session_state["today_question"] = question
        st.session_state["question_date"] = today
    return st.session_state["today_question"]

# --- 3. ëª¨ë¸/í† í¬ë‚˜ì´ì € ë¡œë“œ (ìºì‹±) ---
@st.cache_data(show_spinner="ëª¨ë¸ ë¡œë”© ì¤‘...", persist=True)
def load_model_and_tokenizer():
    model_path = os.path.join(os.path.dirname(__file__), "best_model.pt")
    config = AutoConfig.from_pretrained("klue/bert-base", num_labels=2)
    tokenizer = AutoTokenizer.from_pretrained("klue/bert-base")
    model = AutoModelForSequenceClassification.from_pretrained("klue/bert-base", config=config)
    state = torch.load(model_path, map_location="cpu")
    if "state_dict" in state:
        state = state["state_dict"]
    model.load_state_dict(state, strict=False)
    model.eval()
    return tokenizer, model

# --- 4. ê°ì • ë¶„ë¥˜ ë¡œì§ (Rule â†’ Model â†’ API) ---
POSITIVE_KEYWORDS = ["ì¢‹ì•„ìš”", "í–‰ë³µ", "ê¸°ë»", "ì¬ë¯¸", "ì›ƒ", "ê³ ë§ˆì›Œ", "ì‹ ë‚˜ìš”", "ì¦ê±°", "ì‚¬ë‘"]
NEGATIVE_KEYWORDS = ["ìŠ¬í¼", "ì‹«ì–´", "í™”ë‚˜", "ì§œì¦", "í˜ë“¤", "ìš¸", "ë¬´ì„œì›Œ", "ì•„íŒŒ", "ì™¸ë¡œì›Œ", "ì†ìƒ"]

def rule_based_emotion(text: str):
    for kw in POSITIVE_KEYWORDS:
        if kw in text:
            return "Positive", 1.0, "ë£° ê¸°ë°˜"
    for kw in NEGATIVE_KEYWORDS:
        if kw in text:
            return "Negative", 1.0, "ë£° ê¸°ë°˜"
    return None, None, None

def predict_emotion(text: str, tokenizer, model):
    try:
        inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=128)
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probs = F.softmax(logits, dim=1).cpu().numpy()[0]
            pred = int(probs.argmax())
            label = "Positive" if pred == 1 else "Negative"
            confidence = float(probs[pred])
        return label, confidence, "ëª¨ë¸"
    except Exception as e:
        return None, None, f"ëª¨ë¸ ì˜ˆì™¸: {e}"

def api_emotion(text: str):
    prompt = (
        f"ì•„ë˜ ì–´ë¦°ì´ì˜ ë‹µë³€ì„ ê°ì •(Positive/Negative)ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ì‹ ë¢°ë„(0~1)ë¥¼ í•¨ê»˜ ì•Œë ¤ì¤˜.\n"
        f"ë‹µë³€: \"{text}\"\n"
        f"ê²°ê³¼ëŠ” JSON í˜•ì‹ìœ¼ë¡œ:\n"
        f"{{\"emotion\": \"Positive|Negative\", \"confidence\": 0.0~1.0}}"
    )
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=100,
        )
        import json
        content = response.choices[0].message.content.strip()
        result = json.loads(content)
        return result.get("emotion", "Unknown"), float(result.get("confidence", 0.0)), "API"
    except Exception as e:
        return "ë¶„ì„ ì‹¤íŒ¨", 0.0, f"API ì˜ˆì™¸: {e}"

def classify_emotion(text: str, tokenizer, model, conf_threshold=0.7):
    label, conf, method = rule_based_emotion(text)
    if label:
        return label, conf, method
    label, conf, method = predict_emotion(text, tokenizer, model)
    if label and conf is not None and conf >= conf_threshold:
        return label, conf, method
    label, conf, method = api_emotion(text)
    return label, conf, method

# --- 5. ë¶€ëª¨ìš© ë¦¬í¬íŠ¸ ìƒì„± ---
def generate_parent_report(today_data):
    if not today_data:
        return "ì•„ì§ ì˜¤ëŠ˜ ì•„ì´ì˜ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤."
    prompt = (
        "ì•„ë˜ëŠ” ì•„ì´ì˜ ì˜¤ëŠ˜ ë‹µë³€ê³¼ ê°ì • ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n"
        "ë¶€ëª¨ê°€ ì•„ì´ì™€ ëŒ€í™”í•  ë•Œ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ëŒ€í™”ë²•, ê²©ë ¤, ì£¼ì˜ì  ë“±ì„ 3~5ì¤„ë¡œ ì œì•ˆí•´ì¤˜.\n"
        "ë‹µë³€ì€ ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ ì‘ì„±í•´ì¤˜.\n\n"
    )
    for i, item in enumerate(today_data, 1):
        prompt += (
            f"{i}. ë‹µë³€: \"{item['answer']}\"\n"
            f"   ê°ì •: {item['emotion']} (ì‹ ë¢°ë„: {item['confidence']:.2f})\n"
        )
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=300,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# --- 6. ì„¸ì…˜/ì¸ì¦ ê´€ë¦¬ ---
def reset_session():
    for key in list(st.session_state.keys()):
        del st.session_state[key]

def require_parent_auth():
    if not st.session_state.get("parent_authenticated", False):
        st.markdown("### ğŸ”’ ë¶€ëª¨ ì¸ì¦")
        code = st.text_input("ì¸ì¦ ì½”ë“œ", type="password")
        login = st.button("ë¡œê·¸ì¸")
        if login:
            if code == PARENT_CODE:
                st.session_state["parent_authenticated"] = True
                st.rerun()
            else:
                st.error("âŒ ì½”ë“œ ì˜¤ë¥˜")
        st.stop()

# --- 7. ì‚¬ì´ë“œë°” ë° ë·° ì „í™˜ ---
def sidebar():
    st.sidebar.title("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ë©”ë‰´")
    view = st.sidebar.radio(
        "í™”ë©´ ì„ íƒ",
        options=["Child View", "Parent View"],
        index=0 if st.session_state.get("current_view", "Child View") == "Child View" else 1,
        key="current_view"
    )
    if st.sidebar.button("ë¡œê·¸ì•„ì›ƒ"):
        reset_session()
        st.rerun()
    st.sidebar.markdown("---")
    st.sidebar.caption("Â© 2024 Child-Parent Emotion App")

# --- 8. Child View (ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤) ---
def child_view(tokenizer, model):
    st.markdown(
        "<h2 style='color:#2563eb;'>ğŸ§’ ì˜¤ëŠ˜ì˜ ì§ˆë¬¸</h2>",
        unsafe_allow_html=True
    )
    question = get_today_question()

    # ì±—ë´‡ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []
        st.session_state["chat_history"].append({
            "role": "assistant",
            "content": f"ì•ˆë…•! ì˜¤ëŠ˜ì€ ì´ ì§ˆë¬¸ì— ë‹µí•´ì¤„ë˜? ğŸ’¬\n\n**{question}**"
        })

    # ì±—ë´‡ ë©”ì‹œì§€ í‘œì‹œ (ì˜¤ì§ assistant ë©”ì‹œì§€ë§Œ)
    for msg in st.session_state["chat_history"]:
        if msg["role"] == "assistant":
            st.chat_message("assistant").write(msg["content"])

    # ë‹µë³€ ì…ë ¥
    user_input = st.chat_input("ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.", key="child_input")
    if user_input:
        # 1. ì±—ë´‡ ì‘ë‹µ ìƒì„± (OpenAI API, ì „ì²´ íˆìŠ¤í† ë¦¬ ì „ë‹¬)
        chat_msgs = [{"role": m["role"], "content": m["content"]} for m in st.session_state["chat_history"]]
        chat_msgs.append({"role": "user", "content": user_input})
        try:
            resp = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì•„ë™ìš© ì±—ë´‡ì…ë‹ˆë‹¤."},
                    *chat_msgs
                ],
                temperature=0.6,
                max_tokens=200,
            )
            bot_resp = resp.choices[0].message.content.strip()
        except Exception as e:
            bot_resp = f"ì£„ì†¡í•´ìš”, ë‹µë³€ ìƒì„±ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ({e})"

        # 2. íˆìŠ¤í† ë¦¬ ì €ì¥ ë° assistant ë©”ì‹œì§€ë§Œ ë Œë”
        st.session_state["chat_history"].append({"role": "user", "content": user_input})
        st.session_state["chat_history"].append({"role": "assistant", "content": bot_resp})
        st.chat_message("assistant").write(bot_resp)

        # 3. ê°ì • ë¶„ë¥˜ (ë°±ê·¸ë¼ìš´ë“œ ì €ì¥)
        label, confidence, method = classify_emotion(user_input, tokenizer, model)
        history = st.session_state.setdefault("child_history", [])
        history.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
            "answer": user_input,
            "emotion": label,
            "confidence": confidence,
            "method": method,
        })
        st.session_state["child_history"] = history

        st.rerun()

# --- 9. Parent View ---
def parent_view():
    require_parent_auth()
    st.markdown(
        "<h2 style='color:#f59e42;'>ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ ë¶€ëª¨ ëŒ€ì‹œë³´ë“œ</h2>",
        unsafe_allow_html=True
    )
    history = st.session_state.get("child_history", [])
    today = date.today().isoformat()
    today_data = [h for h in history if h["timestamp"].startswith(today)]

    # ê¸/ë¶€ì • ë¹„ìœ¨
    pos = sum(1 for h in today_data if h["emotion"] == "Positive")
    neg = sum(1 for h in today_data if h["emotion"] == "Negative")
    total = pos + neg
    pos_pct = int(pos / total * 100) if total else 0
    neg_pct = int(neg / total * 100) if total else 0

    col1, col2 = st.columns(2)
    with col1:
        st.metric("ì˜¤ëŠ˜ ê¸ì • ë¹„ìœ¨", f"{pos_pct}%", f"{pos}íšŒ")
    with col2:
        st.metric("ì˜¤ëŠ˜ ë¶€ì • ë¹„ìœ¨", f"{neg_pct}%", f"{neg}íšŒ")

    # ëŒ€í™” ê°€ì´ë“œ
    if st.button("ë¶€ëª¨ ëŒ€í™” ê°€ì´ë“œ ìƒì„±", type="primary"):
        with st.spinner("ê°€ì´ë“œë¥¼ ìƒì„±í•˜ê³  ìˆì–´ìš”..."):
            report = generate_parent_report(today_data)
        st.session_state["parent_report"] = report

    if st.session_state.get("parent_report"):
        st.markdown(
            f"""
            <div style="background:linear-gradient(135deg, #e0f2fe 0%, #f0f9ff 100%);padding:1.5em;border-radius:12px;margin-top:1em;border-left:4px solid #0ea5e9;">
                <h4 style="color:#0ea5e9;margin-top:0;">ğŸ¤— ë¶€ëª¨ë‹˜ì„ ìœ„í•œ ëŒ€í™” íŒ</h4>
                <div style="line-height:1.6;color:#374151;">
                    {st.session_state['parent_report']}
                </div>
            </div>
            """, unsafe_allow_html=True
        )

    # ì˜¤ëŠ˜ ì´ë ¥ í…Œì´ë¸”
    st.markdown("### ì˜¤ëŠ˜ ë‹µë³€ ì´ë ¥")
    if today_data:
        import pandas as pd
        df = pd.DataFrame(today_data)
        df = df[["timestamp", "answer", "emotion", "confidence"]]
        st.dataframe(df, use_container_width=True, hide_index=True)
    else:
        st.info("ì•„ì§ ì˜¤ëŠ˜ ë‹µë³€ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")

# --- 10. ë©”ì¸ ì‹¤í–‰ ---
def main():
    st.set_page_config(
        page_title="Child-Parent Emotion App",
        page_icon="ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    sidebar()
    try:
        tokenizer, model = load_model_and_tokenizer()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()
    if st.session_state.get("current_view", "Child View") == "Child View":
        child_view(tokenizer, model)
    else:
        parent_view()

if __name__ == "__main__":
    main()